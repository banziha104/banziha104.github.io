# K-Clustering

> 각 데이터의 유사성을 측정하여 높은 대상 집단을 분류하고, 군집 간에 상이성을 규명하는 방법 

- Y가 없을떄, 특성을 규명할때 주로 사용
- 종류
    - K-means clustering : 데이터를 사용자가 지정한 k개의 군집으로 나눔
    - Hierarchial clustering : 나무 모양의 계층 구조를 형성해나가는 방법
    - DBSCAN : k개를 설정할 필요 없이 사용  
- K-means clustering 
    - 단계 
        1. 각 데이터 포인트 i에 대해 가장 가까운 중심점을 찾고, 그 중심점에 해당하는 군집 할당 
        2. 할당된 군집을 기반으로 새로운 중심 계산, 중심점은 군집 내부 점들 좌표의 평균으로 함 
        3. 각 클러스터의 할당이 바뀌지 않을 떄 까지 반복
    - 점과 점사이의 거리 측정
        - Manhattan distance : 각 축에 대해 수직으로만 이동하여 계산하는 거리 측정 방식 
        - Euclidean distance : 점과 점사이에 가장 짧은 거리르 계산하는 거리 측정방식
    - 최적의 K찾기
        - 데이터에 최적화된 k를 찾기 어려움.
        - k를 설정하는 대표적인 방법
            - Elbow method : 군집간 분산 (BSS)와 전체분산(TSS = BSS + WSS)의 비율
                - 한계 비용이 줄어드는 지점이 최적의 K
            - Silhouette method :  a(i)(객체i와 객체가 속한 군집의 데이터들과의 비 유사성 )과 b(i)(그 객체가 속하지 않는 군집데이터)를 분석 
        - k-medoids clustering : 변형으로, 평균 대신 중간점을 이용 

- Hierarchical clustering 
    - 개체들을 가까운 집단부터 순차적/계층적으로 묶어나가는 방식
    - 사전에 군집의 개수를 정하지 않아도 수행가능
    - 모든 개체들 사이의 거리에 대한 유사도 행렬 계산
    - 거리가 인접한 관측치끼리 cluster 형성
    - 유사도 행렬 update 
    
- DBSCAN 
    - 한 데이터를 중심으로 엡실론 거리 이내의 데이터들을 한 군집으로 구성
    - MinPts = 변수의 수 + 1
    - Eps의 설정
        - 너무 작은 경우, 상당수의 데이터가 노이즈로 구분
        - 너무 큰 경후, 군집의 수가 하나가 될 가능성이 있음.

