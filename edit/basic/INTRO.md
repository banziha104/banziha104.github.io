# 머신러닝의 기본개념

> 인공지능의 한 분야로, 컴퓨터가 학습할 수 있도록 하는 알고리즘과 기술을 개발하는 분야

- X로 Y를 예측하고 싶다.
- 주어진 데이터를 통해서 입력변수와 출력변수간의 관계를 만드는 함수 f를 만드는 것
- 주어진 데이터 속에서 데이터의 특징을 찾아내는 함수 f를 만드는 것.
- y(출력변수, 종속변수, 반응변수)
- f(모형)
- x (입력변수, 독립변수, feature) 
- 엡실론 : 오차항 (예측치와 실제값의 차이)


<br>

# 지도학습 비지도학습

- 지도학습(supervised learning) : Y = f(X)에 대하여 입력 변수(X)와 출력 변수(Y)의 관계에 대하여 모델링하는 것
    - Y에 대하여 예측 또는 분류하는 문제
    - 회귀(regression) : 입력 변수 X에 대해서 연속형 출력 변수 Y를 예측 (BMI 지수 등)
    - 분류(classification) ; 입력 변수 X에 대해서 이산형 변수 Y(class)를 예측 (감염 여부 등)
- 비지도학습(unsupervised learning) : 출력 변수(Y)가 존재하지 않고, 입력 변수(X)간의 관계에 대해 모델링 하는 것
    - 군집 분석 : 유사한 데이터끼리 그룹화  
    - PCA : 독립변수들의 차원을 축소화
- 강화학습 
    - 수 많은 시뮬레이션을 통해 현재의 선택이 먼 미래에 보상이 최대가 되도록 학습
    - Agent가 action을 취하고 환경에서 보상을 받고 이 보상이 최대가 되도록 최적의 action을 취하는 방법을 배움
    

<br>

# 머신러닝의 종류 

- 지도학습 
    - 선형 회귀분석(Linear Regression)
        - 독립변수와 종속변수가 선형적인 관계가 있다라는 가정하에 분석
        - 직선을 통해 종속변수를 예측하기 때문에 독립변수의 중요도와 영향력을 파악하기 쉬움 
    - 의사결정나무 (Decision Tree)
        - 독립 변수의 조건에 따라 종속변수를 분리
        - 이해하기 쉬우나 과적합(overfitting)이 잘 일어남
        - 앙상블 러닝과 잘 맞음
    - KNN(K-Nearest Neighbor)
        - 새로 들어온 데이터의 주변 k개의 데이터의 class로 분류하는 기법 
    - Neural Network
        - 입력, 은닉, 출력층으로 구성된 모형으로서 각 층을 연결하는 노드의 가중치를 업데이트하면서 학습 
    - SVM (Support Vector Machine)
        - Class 간의 거리가 최대로 되도록 decision boundary를 만드는 방법 
    - Ensemble Leaning 
        - 여러 개의 모델(classifier or base learner)을 결합하여 사용하는 모델 

- 비지도학습 
    - K-means clustering : label 없이 데이터의 군집으로 k개 생성 
    
    
<br>

# 모형의 적합성 평가 및 실험 설계 

- 모형의 적합성을 평가하는 방법
    - 데이터 분할 (5:3:2 비율로 보통 정함)
        - 데이터를 많은 경우
        - training (학습데이터) : 모형 f를 추정하는데 필요 
        - validation(검증데이터) : 추정한 모형 f가 적합한지 검증 
        - test(테스트 데이터) : 최종적으로 선택한 모형의 성능을 평가, 계측 순서를 정확히 해야함 (가장 최신 데이터를 테스트) 
    - k-Fold 교차 검증 (k-Fold Cross Validation)
        - 데이터의 수가 애매하게 많을 때 사용
        - 모형의 적합성을 보다 객관적으로 평가하기 위한 방법
        - 데이터를 k개 부분으로 나눈 뒤 , 그 중하나를 검증 집합, 나머지를 학습 집합으로 분류
        - 위 과정을 k번 반복하고 성능 지표를 평균하여 모형의 적합성 평가 
    - LOOCV(Leave-One-Out Cross Validation) 
        - 데이터의 수가 매우 적을때 사용
        - 총 n개의 모델을 만드는데, 각 모델은 하나의 샘플만 제외하면서 모델을 만들고 제외한 샘플로 성능 지표를 계산함
        - 이렇게 도출된 n개의 성능 지표를 평균 내어 최종 성능 지표를 도출 
- Class imblance : 학습과 검증 데이터의 비율을 z값(신용카드 연체율 등)에 맞춰 분할 (학습 z:1-z 면 검증도 z:1-z)
    - 층화추출 
    
- 데이터 분석 과정 
    1. Raw 데이터
    2. 전처리 된 데이터
    3. 실험설계
    4. Model

- 파생변수 : Raw 데이터를 전처리하여 만든 파라미터 변수
- 전처리 : 어떤 변수가 결과에 영향을 미칠지 생각하면서 파생변수
- 모델 성능을 가장 높이는 방법은 feature(파생변수)를 잘 만드는 것
    
    
<br>

# 과적합 

- 복잡한 모형일수록, 데이터가 적을수록 과적합이 일어나기 쉬움
- 과적합은 data science 뿐만 아니라 AI 전반적인 이슈 
- reducible error : 제거 가능한 에러 (모형)
- inreducible error : 제거 불가능한 에러 (엡실론)
- 분산 : 전체 데이터 집합 중 다른 학습 데이터를 이용했을 때, f^이 변하는 정도 (복잡한 모형일수록 분산이 높음)
- 편파성 : 학습 알고리즘에서 잘못된 가정을 했을때 발생하는 오차 (간한 모형일수록 높음 )
- 복잡한 모형 f^(X)을 사용하여 편파성을 줄이면 , 반대로 분산이 커짐 (트레이드오프, 딜레마)
- 따라서 분산과 편파성이 작은 모형을 찾아야 함.

